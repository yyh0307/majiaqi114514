import whisper
import sounddevice as sd
import numpy as np
import threading
import queue
import pyttsx3
import time

# ===================== æ ¸å¿ƒé…ç½® =====================
SAMPLING_RATE = 16000  # Whisperå›ºå®šè¦æ±‚16000é‡‡æ ·ç‡
CHUNK_DURATION = 5     # æ¯2ç§’è½¬å†™ä¸€æ¬¡ï¼ˆå¯è°ƒï¼Œè¶Šå°è¶Šå®æ—¶ï¼‰
MODEL = "small"         # æ¨¡å‹å¤§å°ï¼štiny(æœ€å¿«)/base(å¹³è¡¡)/small(æ›´å‡†)
LANGUAGE = "zh"        # æŒ‡å®šä¸­æ–‡è½¬å†™ï¼Œæå‡å‡†ç¡®ç‡
KEYWORD = "å°è¨ºåŠ©æ‰‹"    # è§¦å‘å…³é”®è¯
RESPONSE_TEXT = "æ‚¨å¥½ï¼Œè¯·é—®éœ€è¦å¯¼è¯ŠæœåŠ¡è¿˜æ˜¯å®‰å…¨ç›‘æŠ¤ï¼Ÿ"  # å›å¤å†…å®¹

# ===================== åˆå§‹åŒ– =====================
# åŠ è½½Whisperæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½åˆ°æœ¬åœ°ï¼‰
model = whisper.load_model(MODEL, device="cpu")  # å¼ºåˆ¶CPUï¼Œé¿å…GPUä¾èµ–
# éŸ³é¢‘é˜Ÿåˆ—ï¼šå­˜å‚¨é‡‡é›†çš„éŸ³é¢‘æ•°æ®
audio_queue = queue.Queue()
# è¯­éŸ³åˆæˆå¼•æ“åˆå§‹åŒ–
engine = pyttsx3.init()
# è®¾ç½®è¯­éŸ³åˆæˆå‚æ•°
voices = engine.getProperty('voices')
engine.setProperty('voice', voices[0].id)  # é€‰æ‹©ç¬¬ä¸€ä¸ªè¯­éŸ³ï¼ˆä¸­æ–‡ï¼‰
engine.setProperty('rate', 150)  # è®¾ç½®è¯­é€Ÿ
engine.setProperty('volume', 0.9)  # è®¾ç½®éŸ³é‡

# å…¨å±€çŠ¶æ€ï¼šæ˜¯å¦å·²ç»å›å¤è¿‡ï¼Œé¿å…é‡å¤è§¦å‘
has_responded = False
response_lock = threading.Lock()

# ===================== éŸ³é¢‘é‡‡é›†å›è°ƒ =====================
def collect_audio(indata, frames, time, status):
    """éº¦å…‹é£é‡‡é›†å›è°ƒï¼Œç›´æ¥å­˜åŸå§‹éŸ³é¢‘æ•°æ®"""
    if status:
        print(f"é‡‡é›†æç¤ºï¼š{status}", flush=True)
    # è½¬æ¢ä¸ºWhisperè¦æ±‚çš„æ ¼å¼ï¼ˆå•å£°é“ã€float32ï¼‰
    audio_data = indata[:, 0].astype(np.float32)
    audio_queue.put(audio_data)

# ===================== è¯­éŸ³å›å¤å‡½æ•° =====================
def speak_response():
    """è¯­éŸ³å›å¤å‡½æ•°ï¼Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œ"""
    global has_responded
    with response_lock:
        if not has_responded:
            print(f"ğŸ¤ å¼€å§‹è¯­éŸ³å›å¤ï¼š{RESPONSE_TEXT}")
            engine.say(RESPONSE_TEXT)
            engine.runAndWait()
            has_responded = True
            # 30ç§’åé‡ç½®å›å¤çŠ¶æ€ï¼Œå…è®¸å†æ¬¡è§¦å‘
            threading.Timer(30, reset_response_status).start()

def reset_response_status():
    """é‡ç½®å›å¤çŠ¶æ€ï¼Œå…è®¸å†æ¬¡è§¦å‘"""
    global has_responded
    with response_lock:
        has_responded = False
    print("ğŸ”„ å›å¤çŠ¶æ€å·²é‡ç½®ï¼Œå¯ä»¥å†æ¬¡è§¦å‘å…³é”®è¯")

# ===================== å®æ—¶è½¬å†™ä¸å…³é”®è¯æ£€æµ‹çº¿ç¨‹ =====================
def transcribe_and_detect():
    """æŒç»­ä»é˜Ÿåˆ—å–éŸ³é¢‘å¹¶è½¬å†™ï¼ŒåŒæ—¶æ£€æµ‹å…³é”®è¯"""
    print(f"âœ… å¼€å§‹å®æ—¶è½¬å†™ä¸å…³é”®è¯æ£€æµ‹ï¼ˆ{CHUNK_DURATION}ç§’/æ®µï¼‰ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")
    print(f"ğŸ” ç­‰å¾…å…³é”®è¯ï¼š'{KEYWORD}'")
    
    while True:
        # æ”¶é›†æŒ‡å®šæ—¶é•¿çš„éŸ³é¢‘æ•°æ®
        audio_chunks = []
        target_frames = int(SAMPLING_RATE * CHUNK_DURATION)  # ç›®æ ‡æ€»å¸§æ•°
        collected_frames = 0
        
        while collected_frames < target_frames:
            try:
                chunk = audio_queue.get(timeout=1)
                audio_chunks.append(chunk)
                collected_frames += len(chunk)
            except queue.Empty:
                break
        
        # è½¬å†™æœ‰æ•ˆéŸ³é¢‘
        if audio_chunks:
            # æ‹¼æ¥å¹¶å½’ä¸€åŒ–ï¼ˆWhisperå¿…éœ€æ­¥éª¤ï¼‰
            audio = np.concatenate(audio_chunks)
            audio = audio / np.max(np.abs(audio)) if np.max(np.abs(audio)) > 0 else audio
            
            # æ ¸å¿ƒè½¬å†™ï¼šç›´æ¥å¤„ç†åŸå§‹éŸ³é¢‘æ•°ç»„
            result = model.transcribe(
                audio,
                language=LANGUAGE,
                fp16=False,  # å…³é—­åŠç²¾åº¦ï¼Œé€‚é…CPU
                verbose=False  # å…³é—­å†—ä½™æ—¥å¿—
            )
            
            if result["text"].strip():
                print(f"ğŸ“ è½¬å†™ç»“æœï¼š{result['text']}")
                
                # å…³é”®è¯æ£€æµ‹
                with response_lock:
                    if KEYWORD in result["text"] and not has_responded:
                        print(f"ğŸ‰ æ£€æµ‹åˆ°å…³é”®è¯ï¼š'{KEYWORD}'")
                        # å¯åŠ¨è¯­éŸ³å›å¤çº¿ç¨‹
                        threading.Thread(target=speak_response, daemon=True).start()

# ===================== å¯åŠ¨ç¨‹åº =====================
if __name__ == "__main__":
    # å¯åŠ¨è½¬å†™ä¸æ£€æµ‹çº¿ç¨‹
    transcribe_thread = threading.Thread(target=transcribe_and_detect, daemon=True)
    transcribe_thread.start()
    
    # å¯åŠ¨éº¦å…‹é£é‡‡é›†ï¼ˆç›´æ¥è¿æ¥ç¡¬ä»¶é©±åŠ¨ï¼Œæ— ä¸­é—´æ–‡ä»¶ï¼‰
    with sd.InputStream(
        samplerate=SAMPLING_RATE,
        channels=1,  # å•å£°é“
        callback=collect_audio,
        blocksize=1024  # é‡‡é›†å—å¤§å°ï¼Œé€‚é…ç¡¬ä»¶
    ):
        try:
            input()  # é˜»å¡ä¸»çº¿ç¨‹ï¼Œä¿æŒç¨‹åºè¿è¡Œ
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç¨‹åºå·²åœæ­¢")